---
title: 第一次的机器学习：机器学习基础概念和名词
pubDate: 2017-07-30
categories: ["知识课堂"]
tags: 
- 机器学习
---



尽管机器学习从分类上而言只是人工智能（也就是常说的AI）的分支之一，但其本身也是一个相当巨大的命题。在未来的一段时间里，我将花时间在专栏写一些我比较熟悉的机器学习相关的概念和算法，最主要的目的是为了梳理自己的知识体系，也是希望和大家分享学习的历程和感悟，以达到交流的目的。

这两年大数据火了，机器学习、神经网络、数据挖掘、强化学习等等这些名词都火了，然而我常常在想，把这些名词挂在嘴边的我们，究竟能否在这个领域飞速发展的情况下，清楚地了解到自己说的每一个名词——谁是谁的分支，哪个和哪个又是同等关系或是没有关系的——在名词爆炸的状态下，想学什么，了解其基础概念是必不可少的。



#  与数据相关的概念

假如我们有一组天气数据，是来自全世界不同国家和地区的每日天气，内容包括最高温度、最低温度、平均湿度、风速之类的相关数据，例如数据的一部分是这样的：

| 城市   | 最高温度 | 最低温度 | 相对湿度 | 某时刻风速    |
| ---- | ---- | ---- | ---- | -------- |
| A市   | 36℃  | 28℃  | 58%  | 16.7km/h |
| B市   | 28℃  | 17℃  | 86%  | /        |
| C市   | 34℃  | 29℃  | 39%  | 20.4km/h |

在这组数据中，我们将称A市、B市、C市等市以及其情况的总和称为**数据集（data set）**。表格中的每一行，也就是某城市和它的情况被称为一个**样例（sample/instance）**。表格中的每一列（不包括城市），例如最高温度、最低温度，被称为**特征（feature/attribute）**，而每一列中的具体数值，例如36℃ 、28℃，被称为**属性值（attribute value）**。数据中也可能会有**缺失数据（missing data）**，例如B市的某时刻风速，我们会将它视作缺失数据。


如果我们想预测城市的天气，例如是晴朗还是阴雨天，这些数据是不够的，除了**特征**以外，我们还需要每个城市的具体天气情况，也就是通常语境下的结果。在机器学习中，它会被称为**标签（label）**，用于标记数据。值得注意的是，数据集中不一定包含标签信息，而这种区别会引起方法上的差别。我们可以给上述示例加上一组标签：

| 城市   | 天气   |
| ---- | ---- |
| A市   | 晴朗   |
| B市   | 阴雨   |
| C市   | 晴朗   |

视具体情况，用来进行机器学习的一个数据集往往会被分为两个数据集——**训练数据（training data）**和**测试数据（testing data）**。  顾名思义，训练数据在机器学习的过程中使用，目的是找出一套机器学习的方法；而测试数据用于判断找出的方法是否足够有效。如果在训练的过程中需要确定方法的准确度，有时会将训练数据分成**训练集（training set）**和**验证集（validation set）**——验证集合测试数据不同的地方在于验证集在训练过程中使用，而测试数据事实上是在模型建立后才被使用的。

# 与方法相关的概念

根据数据有没有标签，我们可以将机器学习分类为**监督学习（Supervised Learning）**、**无监督学习（Unsupervised Learning）**和**半监督学习（Semi-Supervised Learning）**。

**监督学习**是学习**给定标签**的数据集，比如说有一组病人，给出他们的详细资料，将他们是否已确诊癌症作为标签，然后预测一名（其他的）病人是否会患有癌症，就是一种典型的监督学习。监督学习中也有不同的分类，如果我们训练的结果是得癌症和不得癌症之类**离散的类型**，则称为**分类（Classification）**，如果只有两种类型的话可以进一步称为**二分类（Binary Classification）**；如果我们训练的结果是得癌症的概率为0.87之类**连续的数字**，则称为**回归（Regression）**。

**无监督学习**是学习**没有标签的数据集**，比如在分析大量语句之后，训练出一个模型将较为接近的词分为一类，而后可以根据一个新的词在句子中的用法（和其他信息）将这个词分入某一类中。其中比较微妙的地方在于，这种问题下使用**聚类（Clustering）**（方法）所获得的**簇（Cluster）**（结果），有时候是无法人为地观察出其特征的，但是在得到聚类后，可能会对数据集有新的启发。

**半监督学习**的数据集比较特殊，是部分有标签部分无标签的数据集。由于有标签的数据很多时候需要花大量人力物力去分类和生成，半监督学习也被视作当前机器学习的重要部分。半监督问题往往会**利用一些假设**，将半监督学习转化为传统的监督学习或非监督学习问题。



# 与结果相关的概念

## 二分类问题

衡量结果精度的有一些相关术语，首当其冲的是**准确率（Accuracy）**、**精确率（Precision）**和**召回率（Recall）**。这三个词汇应用于**二分类问题**：将数据分为**正例（Positive Class）**和**反例（Negative Class）**

一张形象的维基百科图：![](https://upload.wikimedia.org/wikipedia/commons/2/26/Precisionrecall.svg)

也就是说，**准确率**是预测和标签一致的样本在所有样本中所占的比例；**精确率**是你预测为正类的数据中，有多少确实是正类；**召回率**是所有正类的数据中，你预测为正类的数据有多少。这三个数据往往用来衡量一个二分类算法的优劣。

## 回归问题

回归问题往往会通过计算**误差（Error）**来确定模型的精确性。误差由于训练集和验证集的不同，会被分为**训练误差（Training Error）**和**验证误差（Validation Error）**。但值得注意的是，模型并不是误差越小就一定越好，因为如果仅仅基于误差，我们可能会得到一个**过拟合（Overfitting）**的模型；但是如果不考虑误差，我们可能会得到一个**欠拟合（Underfitting）**的模型，用图像来说的话大致可以这样理解：

![](https://3gp10c1vpy442j63me73gy3s-wpengine.netdna-ssl.com/wp-content/uploads/2018/03/Screen-Shot-2018-03-22-at-11.22.15-AM-e1526498075543.png)

如果模型十分简单，往往会欠拟合，对于训练数据和测试数据的误差都会很大；但如果模型太过于复杂，往往会过拟合，那么训练数据的误差可能相当小，但是测试数据的误差会增大。好的模型应当平衡于这两者之间：

![](https://i.stack.imgur.com/S0tRm.png)

## 聚类问题

聚类问题的标准一般基于距离：**簇内距离（Intra-cluster Distance）**和**簇间距离（Inter-cluster Distance）**。根据常识而言，簇内距离是越小越好，也就是簇内的元素越相似越好；而簇间距离越大越好，也就是说簇间（不同簇）元素越不相同越好。一般来说，衡量聚类问题会给出一个结合簇内距离和簇间距离的公式。



# 总结

机器学习的基本概念并不多，但搞清楚具体每个算法适用于怎样的数据、应当怎样去评价是比较重要的一点。

在之后的专栏中，我们将更多的讨论具体的算法，比较它们的优劣，研究它们的局限性和适用性。

希望大家在了解机器学习的时候把一句话永远放在心中：

> All models are wrong but some are useful.